{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.801768Z","iopub.status.busy":"2023-04-15T15:42:36.801522Z","iopub.status.idle":"2023-04-15T15:42:36.805739Z","shell.execute_reply":"2023-04-15T15:42:36.804951Z","shell.execute_reply.started":"2023-04-15T15:42:36.801744Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ethsi\\.conda\\envs\\yusen\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from tqdm import tqdm\n","import torch.backends.cudnn as cudnn"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.808020Z","iopub.status.busy":"2023-04-15T15:42:36.807814Z","iopub.status.idle":"2023-04-15T15:42:36.849948Z","shell.execute_reply":"2023-04-15T15:42:36.849236Z","shell.execute_reply.started":"2023-04-15T15:42:36.807996Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;li&gt;&lt;a href=\"/wiki/File:Socrates.png\" class=\"i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;tt onmouseover=\"alert(1)\"&gt;test&lt;/tt&gt;</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;Steeri...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;&lt;cite ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\\t &lt;/span&gt;. &lt;a href=\"/wiki/Digital_object_iden...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Sentence  Label\n","0  <li><a href=\"/wiki/File:Socrates.png\" class=\"i...      0\n","1               <tt onmouseover=\"alert(1)\">test</tt>      1\n","2  \\t </span> <span class=\"reference-text\">Steeri...      0\n","3  \\t </span> <span class=\"reference-text\"><cite ...      0\n","4  \\t </span>. <a href=\"/wiki/Digital_object_iden...      0"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('XSS_dataset.csv', index_col = 0)\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.852467Z","iopub.status.busy":"2023-04-15T15:42:36.851777Z","iopub.status.idle":"2023-04-15T15:42:36.864438Z","shell.execute_reply":"2023-04-15T15:42:36.863244Z","shell.execute_reply.started":"2023-04-15T15:42:36.852434Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;li&gt;&lt;a href=\"/wiki/File:Socrates.png\" class=\"i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;tt onmouseover=\"alert(1)\"&gt;test&lt;/tt&gt;</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;Steeri...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;&lt;cite ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\\t &lt;/span&gt;. &lt;a href=\"/wiki/Digital_object_iden...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10943</th>\n","      <td>\\t &lt;/span&gt; &lt;/li&gt;</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10944</th>\n","      <td>&lt;li&gt;&lt;a href=\"/wiki/William_Whewell\" title=\"Wil...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10945</th>\n","      <td>&lt;li&gt;&lt;a href=\"/wiki/Niklas_Luhmann\" title=\"Nikl...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10946</th>\n","      <td>&lt;sub onmousedown=\"alert(1)\"&gt;test&lt;/sub&gt;</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10947</th>\n","      <td>&lt;h1 onpointerleave=alert(1)&gt;XSS&lt;/h1&gt;</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10948 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                Sentence  Label\n","0      <li><a href=\"/wiki/File:Socrates.png\" class=\"i...      0\n","1                   <tt onmouseover=\"alert(1)\">test</tt>      1\n","2      \\t </span> <span class=\"reference-text\">Steeri...      0\n","3      \\t </span> <span class=\"reference-text\"><cite ...      0\n","4      \\t </span>. <a href=\"/wiki/Digital_object_iden...      0\n","...                                                  ...    ...\n","10943                                   \\t </span> </li>      0\n","10944  <li><a href=\"/wiki/William_Whewell\" title=\"Wil...      0\n","10945  <li><a href=\"/wiki/Niklas_Luhmann\" title=\"Nikl...      0\n","10946             <sub onmousedown=\"alert(1)\">test</sub>      1\n","10947               <h1 onpointerleave=alert(1)>XSS</h1>      1\n","\n","[10948 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# split train and test\n","train_df = df[:int(len(df)*0.8)]\n","test_df = df[int(len(df)*0.8):]\n","train_df"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<li><a href=\"/wiki/File:Socrates.png\" class=\"image\"><img alt=\"Socrates.png\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/18px-Socrates.png\" decoding=\"async\" width=\"18\" height=\"28\" class=\"noviewer\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/27px-Socrates.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/36px-Socrates.png 2x\" data-file-width=\"326\" data-file-height=\"500\" /> </a> <a href=\"/wiki/Portal:Philosophy\" title=\"Portal:Philosophy\">Philosophy&#32;portal </a> </li> </ul>\n"]}],"source":["sentence_flask = train_df['Sentence'].values[0]\n","# sentence = <tt onmouseover=\"alert(1)\">test</tt>\n","label_flask = train_df['Label'].values[0]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.866144Z","iopub.status.busy":"2023-04-15T15:42:36.865889Z","iopub.status.idle":"2023-04-15T15:42:36.874380Z","shell.execute_reply":"2023-04-15T15:42:36.873806Z","shell.execute_reply.started":"2023-04-15T15:42:36.866117Z"},"trusted":true},"outputs":[],"source":["def data2char_index(data, max_len):\n","    alphabet = \" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n","    mat = []\n","    for ch in data:\n","        if ch not in alphabet:\n","            continue\n","        mat.append(alphabet.index(ch))\n","    if len(mat) < max_len:\n","        mat += [0] * (max_len - len(mat))\n","    elif len(mat) > max_len:\n","        mat = mat[:max_len]\n","    return mat"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.875374Z","iopub.status.busy":"2023-04-15T15:42:36.875161Z","iopub.status.idle":"2023-04-15T15:42:36.891613Z","shell.execute_reply":"2023-04-15T15:42:36.890423Z","shell.execute_reply.started":"2023-04-15T15:42:36.875350Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(10948, 2738)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, df, max_len) -> None:\n","        self.df = df\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        sentence = self.df['Sentence'].values[index]\n","        label = self.df['Label'].values[index]\n","        return torch.tensor(data2char_index(sentence, self.max_len)), torch.tensor(label)\n","\n","\n","sentence_flask = train_df['Sentence'].values[0]\n","# sentence = <tt onmouseover=\"alert(1)\">test</tt>\n","label_flask = train_df['Label'].values[0]\n","max_len = 1000\n","#Preprocess the sentence\n","processed_sentence_flask = data2char_index(sentence_flask, max_len)\n","processed_label_flask = label_flask\n","\n","#Torched the sentence\n","torched_sentence_flask = torch.tensor(processed_sentence_flask)\n","torched_label_flask = torch.tensor(processed_label_flask)\n","\n","trainDataset = Dataset(train_df, 1000)\n","testDataset = Dataset(test_df, 1000)\n","len(trainDataset), len(testDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.895174Z","iopub.status.busy":"2023-04-15T15:42:36.894930Z","iopub.status.idle":"2023-04-15T15:42:36.920870Z","shell.execute_reply":"2023-04-15T15:42:36.920194Z","shell.execute_reply.started":"2023-04-15T15:42:36.895148Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 1000])\n","torch.Size([128])\n"]}],"source":["trainGenerator = torch.utils.data.DataLoader(trainDataset, batch_size=128, shuffle=True)\n","testGenerator = torch.utils.data.DataLoader(testDataset, batch_size=128, shuffle=True)\n","for data, label in trainGenerator:\n","    print(data.shape)\n","    print(label.shape)\n","    break"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.922184Z","iopub.status.busy":"2023-04-15T15:42:36.921952Z","iopub.status.idle":"2023-04-15T15:42:36.943459Z","shell.execute_reply":"2023-04-15T15:42:36.942997Z","shell.execute_reply.started":"2023-04-15T15:42:36.922156Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[ 0.2185, -0.8211]], grad_fn=<AddmmBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["class TextCNN(torch.nn.Module):\n","    def __init__(self, vocab_size, embedding_size, num_classes, kernel_sizes, num_kernels):\n","        super(TextCNN, self).__init__()\n","        self.embedding = torch.nn.Embedding(vocab_size, embedding_size)\n","        self.convs = torch.nn.ModuleList(\n","            [torch.nn.Conv2d(1, num_kernels, (K, embedding_size)) for K in kernel_sizes])\n","        self.dropout = torch.nn.Dropout(0.5)\n","        self.fc = torch.nn.Linear(len(kernel_sizes) * num_kernels, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)  # [batch_size, sequence_length, embedding_size]\n","        x = x.unsqueeze(1)  # [batch_size, 1, sequence_length, embedding_size]\n","        x = [torch.nn.functional.relu(conv(x)).squeeze(3) for conv in self.convs]  # [batch_size, num_kernels, sequence_length - kernel_size + 1] * len(kernel_sizes)\n","        x = [torch.nn.functional.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [batch_size, num_kernels] * len(kernel_sizes)\n","        x = torch.cat(x, 1) # [batch_size, num_kernels * len(kernel_sizes)]\n","        x = self.dropout(x)  # (N, len(Ks)*Co)\n","        logit = self.fc(x)  # (N, C)\n","        return logit\n","\n","model = TextCNN(vocab_size=70, embedding_size=64, num_classes=2, kernel_sizes=[3, 4, 5], num_kernels=128)\n","model(torch.tensor(data2char_index('hello world', 1000)).unsqueeze(0))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.945344Z","iopub.status.busy":"2023-04-15T15:42:36.944571Z","iopub.status.idle":"2023-04-15T15:42:36.950312Z","shell.execute_reply":"2023-04-15T15:42:36.949390Z","shell.execute_reply.started":"2023-04-15T15:42:36.945311Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss = torch.nn.CrossEntropyLoss()\n","epochs = 10"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T15:42:36.951502Z","iopub.status.busy":"2023-04-15T15:42:36.951281Z","iopub.status.idle":"2023-04-15T15:42:36.976497Z","shell.execute_reply":"2023-04-15T15:42:36.975515Z","shell.execute_reply.started":"2023-04-15T15:42:36.951465Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 24.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 0, loss: 2.6998521207133308e-05Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 1, loss: 0.0001227237080456689Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 2, loss: 0.0003590828273445368Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 3, loss: 2.535591193009168e-05Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 26.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 4, loss: 0.00012331618927419186Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 5, loss: 8.4545390564017e-06Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 6, loss: 0.00036836578510701656Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 7, loss: 0.0029694533441215754Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 26.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 8, loss: 0.0003497801080811769Test accuracy: 0.9989043097151206\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 86/86 [00:03<00:00, 25.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch: 9, loss: 0.0012010738719254732Test accuracy: 0.9989043097151206\n"]}],"source":["# use GPU to train\n","model = model.cuda()\n","for epoch in range(epochs):\n","    model.train()\n","    for data, label in tqdm(trainGenerator):\n","        data = data.cuda()\n","        label = label.cuda()\n","        optimizer.zero_grad()\n","        output = model(data)\n","        l = loss(output, label)\n","        l.backward()\n","        optimizer.step()\n","    print(f'epoch: {epoch}, loss: {l}', end=\"\")\n","    torch.save({'epoch': epoch,\n","                    'model': model,\n","                    'optimizer': optimizer},\n","                   'checkpoint_textcnn.pth.tar')\n","    # eval\n","    # model = torch.load('checkpoint_textcnn.pth.tar')['model']\n","    model.cuda()\n","    model.eval()\n","    right_num = 0\n","    for data, label in testGenerator:\n","        data = data.cuda()\n","        label = label.cuda()\n","        output = model(data)\n","        right_num += (torch.argmax(output, dim=1) == label).sum().item()\n","    print(f\"Test accuracy: {right_num / len(testDataset)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# eval"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.status.busy":"2023-04-15T15:42:36.977253Z","iopub.status.idle":"2023-04-15T15:42:36.977546Z","shell.execute_reply":"2023-04-15T15:42:36.977399Z","shell.execute_reply.started":"2023-04-15T15:42:36.977386Z"},"trusted":true},"outputs":[],"source":["class Eval():\n","    def __init__(self):\n","        self.tp = 0\n","        self.fp = 0\n","        self.fn = 0\n","        self.tn = 0\n","\n","    def add(self, pred, label):\n","        if pred == 1 and label == 1:\n","            self.tp += 1\n","        elif pred == 1 and label == 0:\n","            self.fp += 1\n","        elif pred == 0 and label == 1:\n","            self.fn += 1\n","        elif pred == 0 and label == 0:\n","            self.tn += 1\n","\n","    def accuracy(self):\n","        return (self.tp + self.tn) / (self.tp + self.fp + self.fn + self.tn)\n","\n","    def precision(self):\n","        return self.tp / (self.tp + self.fp)\n","\n","    def recall(self):\n","        return self.tp / (self.tp + self.fn)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["model = 0"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.status.busy":"2023-04-15T15:42:36.979729Z","iopub.status.idle":"2023-04-15T15:42:36.980081Z","shell.execute_reply":"2023-04-15T15:42:36.979933Z","shell.execute_reply.started":"2023-04-15T15:42:36.979916Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy: 0.9989043097151206\n","precision: 1.0\n","recall: 0.9979550102249489\n"]}],"source":["eval = Eval()\n","model = torch.load('checkpoint_textcnn.pth.tar')['model']\n","model.cuda()\n","model.eval()\n","for data, label in testGenerator:\n","    data = data.cuda()\n","    label = label\n","    output = model(data).argmax(dim=1).cpu()\n","    for pred, l in zip(output, label):\n","        eval.add(pred, l)\n","print(f\"accuracy: {eval.accuracy()}\")\n","print(f\"precision: {eval.precision()}\")\n","print(f\"recall: {eval.recall()}\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0])\n"]}],"source":["class TextCNN(torch.nn.Module):\n","    def __init__(self, vocab_size, embedding_size, num_classes, kernel_sizes, num_kernels):\n","        super(TextCNN, self).__init__()\n","        self.embedding = torch.nn.Embedding(vocab_size, embedding_size)\n","        self.convs = torch.nn.ModuleList(\n","            [torch.nn.Conv2d(1, num_kernels, (K, embedding_size)) for K in kernel_sizes])\n","        self.dropout = torch.nn.Dropout(0.5)\n","        self.fc = torch.nn.Linear(len(kernel_sizes) * num_kernels, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)  # [batch_size, sequence_length, embedding_size]\n","        x = x.unsqueeze(1)  # [batch_size, 1, sequence_length, embedding_size]\n","        x = [torch.nn.functional.relu(conv(x)).squeeze(3) for conv in self.convs]  # [batch_size, num_kernels, sequence_length - kernel_size + 1] * len(kernel_sizes)\n","        x = [torch.nn.functional.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [batch_size, num_kernels] * len(kernel_sizes)\n","        x = torch.cat(x, 1) # [batch_size, num_kernels * len(kernel_sizes)]\n","        x = self.dropout(x)  # (N, len(Ks)*Co)\n","        logit = self.fc(x)  # (N, C)\n","        return logit\n","    \n","#What is the mat?\n","def data2char_index(data, max_len):\n","    alphabet = \" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n","    mat = []\n","    for ch in data:\n","        if ch not in alphabet:\n","            continue\n","        mat.append(alphabet.index(ch))\n","    if len(mat) < max_len:\n","        mat += [0] * (max_len - len(mat))\n","    elif len(mat) > max_len:\n","        mat = mat[:max_len]\n","    return mat\n","\n","def modelService():\n","    sentence_flask = train_df['Sentence'].values[0]\n","# sentence = <tt onmouseover=\"alert(1)\">test</tt>\n","    label_flask = train_df['Label'].values[0]\n","    max_len = 1000\n","#Preprocess the sentence\n","    processed_sentence_flask = data2char_index(sentence_flask, max_len)\n","    processed_label_flask = label_flask\n","\n","#Torched the sentence\n","    torched_sentence_flask = torch.tensor(processed_sentence_flask)\n","    torched_label_flask = torch.tensor(processed_label_flask)\n","    model = torch.load('checkpoint_textcnn.pth.tar')['model']\n","    model.cuda()\n","    model.eval()\n","    data = torched_sentence_flask.unsqueeze(0).cuda()\n","    label = torched_label_flask\n","    output = model(data).argmax(dim=1).cpu()\n","    print(output)\n","\n","modelService(data2char_index)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":4}
